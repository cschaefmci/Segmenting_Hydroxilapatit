{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7E1KUC79yYb",
    "outputId": "9335d15f-8046-492d-9e51-5d0e1153fec6"
   },
   "outputs": [],
   "source": [
    "#to aquire full access to the data, connect the google drive folder to this Notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK3h4rA491yf"
   },
   "outputs": [],
   "source": [
    "!rm -rf /root/.cache/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMlsAHBi92WT",
    "outputId": "80842b07-7677-4c2d-ec4b-a702bc83edad"
   },
   "outputs": [],
   "source": [
    "!pip install -U --index-url https://download.pytorch.org/whl/cu121 \\\n",
    "  torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZXN2xTT-WYn",
    "outputId": "4eb25320-3fa2-4c50-ee9a-45dc9d9fadfd"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.36.2\n",
    "#Datasets to prepare data and monai if you want to use special loss functions\n",
    "!pip install datasets\n",
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQVQjLnj-U50"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "722c2owWJIxH",
    "outputId": "65228c4d-3115-4762-8554-cdefa586b487"
   },
   "outputs": [],
   "source": [
    "!pip install -U --index-url https://download.pytorch.org/whl/cu121 \\\n",
    "  torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ha-kbW4h-aPD",
    "outputId": "a7aa32da-3ef2-44f9-f901-ddc33a7a83ea"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset as HFDataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import SamProcessor, SamModel\n",
    "import monai\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from scipy import ndimage\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2Zx-JUO-cl5",
    "outputId": "eb67c9e7-aeb0-4b94-ea90-9cffd799406a"
   },
   "outputs": [],
   "source": [
    "# upload the prepared .npy-files\n",
    "\n",
    "# train dataset\n",
    "train_images = np.load(\"/content/drive/MyDrive/Colab Notebooks/Bachelor/patched_images/train_images_filtered_blacked.npy\")\n",
    "train_masks = np.load(\"/content/drive/MyDrive/Colab Notebooks/Bachelor/patched_images/train_masks_filtered_blacked.npy\")\n",
    "\n",
    "print(\"Training data loaded:\", train_images.shape, train_masks.shape)\n",
    "\n",
    "# validation dataset\n",
    "val_images = np.load(\"/content/drive/MyDrive/Colab Notebooks/Bachelor/patched_images/val_images_filtered_blacked.npy\")\n",
    "val_masks = np.load(\"/content/drive/MyDrive/Colab Notebooks/Bachelor/patched_images/val_masks_filtered_blacked.npy\")\n",
    "\n",
    "print(\"Validation data loaded:\", val_images.shape, val_masks.shape)\n",
    "\n",
    "# In HuggingFace Dataset umwandeln\n",
    "train_dataset = HFDataset.from_dict({\n",
    "    \"image\": [Image.fromarray(img) for img in train_images],\n",
    "    \"label\": [Image.fromarray(mask) for mask in train_masks],\n",
    "})\n",
    "val_dataset = HFDataset.from_dict({\n",
    "    \"image\": [Image.fromarray(img) for img in val_images],\n",
    "    \"label\": [Image.fromarray(mask) for mask in val_masks],\n",
    "})\n",
    "\n",
    "train_dataset\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "nIczDy40B-Zo",
    "outputId": "dedfc116-02da-4c4b-bc53-32d43a94ab9c"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_num = random.randint(0, train_images.shape[0]-1)\n",
    "example_image = train_dataset[img_num][\"image\"]\n",
    "example_mask = train_dataset[img_num][\"label\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the first image on the left\n",
    "axes[0].imshow(np.array(example_image), cmap='gray')  # Assuming the first image is grayscale\n",
    "axes[0].set_title(\"Image\")\n",
    "\n",
    "# Plot the second image on the right\n",
    "axes[1].imshow(example_mask, cmap='gray')  # Assuming the second image is grayscale\n",
    "axes[1].set_title(\"Mask\")\n",
    "\n",
    "# Hide axis ticks and labels\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "# Display the images side by side\n",
    "plt.show()\n",
    "\n",
    "[ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "6dIGWGGV6Wat",
    "outputId": "ce2b9ed2-648d-4cd0-d81d-bc93506af746"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def bbox_from_mask(mask: np.ndarray):\n",
    "    \"\"\"Berechnet eine achsenparallele Box aus einer Bin√§rmaske.\"\"\"\n",
    "    m = np.asarray(mask)\n",
    "    if m.ndim == 3:\n",
    "        m = m[..., 0]\n",
    "    if m.dtype != np.uint8:\n",
    "        m = m.astype(np.uint8)\n",
    "    if m.max() > 1:\n",
    "        m = (m > 127).astype(np.uint8)\n",
    "\n",
    "    ys, xs = np.where(m > 0)\n",
    "    if xs.size == 0:\n",
    "        return None\n",
    "    x0, x1 = int(xs.min()), int(xs.max())\n",
    "    y0, y1 = int(ys.min()), int(ys.max())\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "def _ensure_xyxy(bbox):\n",
    "    \"\"\"Saniert Eingabe und korrigiert vertauschte Koordinaten.\"\"\"\n",
    "    arr = np.asarray(bbox, dtype=float).reshape(-1)\n",
    "    if arr.size != 4:\n",
    "        raise ValueError(f\"bbox erwartet vier Werte, erhalten: {arr}\")\n",
    "    x0, y0, x1, y1 = arr.tolist()\n",
    "    if x1 < x0:\n",
    "        x0, x1 = x1, x0\n",
    "    if y1 < y0:\n",
    "        y0, y1 = y1, y0\n",
    "    if x1 == x0:\n",
    "        x1 = x0 + 1.0\n",
    "    if y1 == y0:\n",
    "        y1 = y0 + 1.0\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "def jitter_bbox(bbox, H, W,\n",
    "                trans_px=10,\n",
    "                scale_min=0.9,\n",
    "                scale_max=1.1,\n",
    "                min_size=1):\n",
    "    \"\"\"\n",
    "    Jittert eine Box durch Translation und Skalierung und beschneidet sicher auf das Bild.\n",
    "    H und W sind Bildhoehe und Bildbreite.\n",
    "    Rueckgabeformat: np.array([x0, y0, x1, y1], dtype=np.int64)\n",
    "    \"\"\"\n",
    "    x0, y0, x1, y1 = _ensure_xyxy(bbox)\n",
    "    w = max(x1 - x0, 1.0)\n",
    "    h = max(y1 - y0, 1.0)\n",
    "    cx = x0 + 0.5 * w\n",
    "    cy = y0 + 0.5 * h\n",
    "\n",
    "    s  = float(np.random.uniform(scale_min, scale_max))\n",
    "    tx = float(np.random.randint(-trans_px, trans_px + 1)) if trans_px > 0 else 0.0\n",
    "    ty = float(np.random.randint(-trans_px, trans_px + 1)) if trans_px > 0 else 0.0\n",
    "\n",
    "    new_w = max(w * s, float(min_size))\n",
    "    new_h = max(h * s, float(min_size))\n",
    "\n",
    "    nx0 = int(round(cx - 0.5 * new_w + tx))\n",
    "    ny0 = int(round(cy - 0.5 * new_h + ty))\n",
    "    nx1 = nx0 + int(round(new_w))\n",
    "    ny1 = ny0 + int(round(new_h))\n",
    "\n",
    "    nx0 = max(0, min(nx0, W - 2))\n",
    "    ny0 = max(0, min(ny0, H - 2))\n",
    "    nx1 = max(nx0 + 1, min(nx1, W - 1))\n",
    "    ny1 = max(ny0 + 1, min(ny1, H - 1))\n",
    "\n",
    "    return np.array([nx0, ny0, nx1, ny1], dtype=np.int64)\n",
    "\n",
    "# Zuf√§lligen Index w√§hlen\n",
    "idx = random.randrange(len(train_dataset))\n",
    "example_image = np.array(train_dataset[idx][\"image\"])\n",
    "example_mask  = np.array(train_dataset[idx][\"label\"])\n",
    "\n",
    "# Boxen bestimmen\n",
    "bbox = bbox_from_mask(example_mask)\n",
    "H, W = example_mask.shape[:2]\n",
    "use_jitter = True  # auf False setzen, falls nur die Originalbox gezeigt werden soll\n",
    "bbox_j = jitter_bbox(bbox, H, W) if (bbox is not None and use_jitter) else None\n",
    "\n",
    "# Darstellung\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Bild links\n",
    "axes[0].imshow(example_image, cmap=\"gray\")\n",
    "axes[0].set_title(\"Bild\")\n",
    "axes[0].set_xticks([]); axes[0].set_yticks([])\n",
    "\n",
    "# Maske rechts\n",
    "axes[1].imshow(example_mask, cmap=\"gray\")\n",
    "axes[1].set_title(\"Maske\")\n",
    "axes[1].set_xticks([]); axes[1].set_yticks([])\n",
    "\n",
    "# Boxen einzeichnen\n",
    "if bbox is not None:\n",
    "    x0, y0, x1, y1 = bbox\n",
    "    w0, h0 = x1 - x0, y1 - y0\n",
    "    for ax in axes:\n",
    "        ax.add_patch(Rectangle((x0, y0), w0, h0,\n",
    "                               fill=False, linewidth=2, edgecolor=\"lime\"))\n",
    "if bbox_j is not None:\n",
    "    x0, y0, x1, y1 = bbox_j\n",
    "    wj, hj = x1 - x0, y1 - y0\n",
    "    for ax in axes:\n",
    "        ax.add_patch(Rectangle((x0, y0), wj, hj,\n",
    "                               fill=False, linewidth=2, edgecolor=\"orange\"))\n",
    "\n",
    "if bbox is None:\n",
    "    fig.suptitle(\"Keine Objektmaske im gew√§hlten Patch\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_37vO6s8p-f"
   },
   "outputs": [],
   "source": [
    "def _ensure_xyxy(bbox):\n",
    "    arr = np.asarray(bbox, dtype=float).reshape(-1)\n",
    "    if arr.size != 4:\n",
    "        raise ValueError(f\"bbox erwartet vier Werte, erhalten: {arr}\")\n",
    "    x0, y0, x1, y1 = arr.tolist()\n",
    "    if x1 < x0:\n",
    "        x0, x1 = x1, x0\n",
    "    if y1 < y0:\n",
    "        y0, y1 = y1, y0\n",
    "    if x1 == x0:\n",
    "        x1 = x0 + 1.0\n",
    "    if y1 == y0:\n",
    "        y1 = y0 + 1.0\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "def get_bounding_box(mask, pad=20):\n",
    "    y, x = np.where(mask > 0)\n",
    "    H, W = mask.shape\n",
    "    if x.size == 0:\n",
    "        # Vollbild als Fallback\n",
    "        x0, y0, x1, y1 = 0, 0, W - 1, H - 1\n",
    "    else:\n",
    "        x_min, x_max = int(x.min()), int(x.max())\n",
    "        y_min, y_max = int(y.min()), int(y.max())\n",
    "        # zuf√§llige Erweiterung\n",
    "        x0 = max(0, x_min - np.random.randint(0, pad + 1))\n",
    "        y0 = max(0, y_min - np.random.randint(0, pad + 1))\n",
    "        x1 = min(W - 1, x_max + np.random.randint(0, pad + 1))\n",
    "        y1 = min(H - 1, y_max + np.random.randint(0, pad + 1))\n",
    "        x0, y0, x1, y1 = _ensure_xyxy([x0, y0, x1, y1])\n",
    "\n",
    "    # harte Klippen und Mindestbreite sowie Mindesth√∂he sichern\n",
    "    x0 = max(0, min(int(x0), W - 2))\n",
    "    y0 = max(0, min(int(y0), H - 2))\n",
    "    x1 = max(x0 + 1, min(int(x1), W - 1))\n",
    "    y1 = max(y0 + 1, min(int(y1), H - 1))\n",
    "    return [x0, y0, x1, y1]\n",
    "\n",
    "def jitter_bbox(bbox, H, W, trans_px=10, scale_min=0.9, scale_max=1.1, min_size=1):\n",
    "    x0, y0, x1, y1 = _ensure_xyxy(bbox)\n",
    "    w = max(x1 - x0, 1.0)\n",
    "    h = max(y1 - y0, 1.0)\n",
    "    cx = x0 + 0.5 * w\n",
    "    cy = y0 + 0.5 * h\n",
    "\n",
    "    s  = float(np.random.uniform(scale_min, scale_max))\n",
    "    tx = float(np.random.randint(-trans_px, trans_px + 1)) if trans_px > 0 else 0.0\n",
    "    ty = float(np.random.randint(-trans_px, trans_px + 1)) if trans_px > 0 else 0.0\n",
    "\n",
    "    new_w = max(w * s, float(min_size))\n",
    "    new_h = max(h * s, float(min_size))\n",
    "\n",
    "    nx0 = int(round(cx - 0.5 * new_w + tx))\n",
    "    ny0 = int(round(cy - 0.5 * new_h + ty))\n",
    "    nx1 = nx0 + int(round(new_w))\n",
    "    ny1 = ny0 + int(round(new_h))\n",
    "\n",
    "    nx0 = max(0, min(nx0, W - 2))\n",
    "    ny0 = max(0, min(ny0, H - 2))\n",
    "    nx1 = max(nx0 + 1, min(nx1, W - 1))\n",
    "    ny1 = max(ny0 + 1, min(ny1, H - 1))\n",
    "\n",
    "    return np.array([nx0, ny0, nx1, ny1], dtype=np.int64)\n",
    "\n",
    "# ---------- Datensatz ----------\n",
    "\n",
    "class SAMDatasetV2(Dataset):\n",
    "    def __init__(self, dataset, processor,\n",
    "                 use_jitter=True, trans_px=40, scale_min=0.7, scale_max=1.4, pad=20):\n",
    "        if isinstance(dataset, SAMDatasetV2):\n",
    "            dataset = dataset.dataset\n",
    "        self.dataset    = dataset          # erwartet Felder 'image' und 'label'\n",
    "        self.processor  = processor        # SamProcessor aus transformers\n",
    "        self.use_jitter = use_jitter\n",
    "        self.trans_px   = trans_px\n",
    "        self.scale_min  = scale_min\n",
    "        self.scale_max  = scale_max\n",
    "        self.pad        = pad\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item  = self.dataset[idx]\n",
    "        image = item[\"image\"]                      # PIL oder np.ndarray\n",
    "        mask  = np.array(item[\"label\"]).astype(np.uint8)\n",
    "\n",
    "        H, W = mask.shape\n",
    "        base_bbox = get_bounding_box(mask, pad=self.pad)\n",
    "\n",
    "        # robustes Jittering mit Fallback\n",
    "        try:\n",
    "            bbox_np = jitter_bbox(\n",
    "                base_bbox, H, W,\n",
    "                trans_px=self.trans_px,\n",
    "                scale_min=self.scale_min,\n",
    "                scale_max=self.scale_max\n",
    "            ) if self.use_jitter else np.array(base_bbox, dtype=np.int64)\n",
    "        except Exception:\n",
    "            x0, y0, x1, y1 = _ensure_xyxy(base_bbox)\n",
    "            x0 = max(0, min(int(x0), W - 2))\n",
    "            y0 = max(0, min(int(y0), H - 2))\n",
    "            x1 = max(x0 + 1, min(int(x1), W - 1))\n",
    "            y1 = max(y0 + 1, min(int(y1), H - 1))\n",
    "            bbox_np = np.array([x0, y0, x1, y1], dtype=np.int64)\n",
    "\n",
    "        # durch den Processor schicken, damit Boxen zur Modellaufl√∂sung transformiert werden\n",
    "        enc = self.processor(\n",
    "            images=image,\n",
    "            input_boxes=[[bbox_np.tolist()]],   # Form [batch, num_boxes, 4]\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        pixel_values = enc[\"pixel_values\"].squeeze(0)   # [3, Hs, Ws]\n",
    "\n",
    "        # der Processor liefert input_boxes je nach Version als Liste oder Tensor\n",
    "        ib = enc[\"input_boxes\"]\n",
    "        if isinstance(ib, list):\n",
    "            input_boxes = ib[0]                         # Tensor [num_boxes, 4]\n",
    "        else:\n",
    "            input_boxes = ib.squeeze(0)                 # [num_boxes, 4]\n",
    "        # f√ºr das Modell erwarten wir [1, 4]\n",
    "        if input_boxes.ndim == 1:\n",
    "            input_boxes = input_boxes.unsqueeze(0)\n",
    "\n",
    "        sample = {\n",
    "            \"pixel_values\": pixel_values,                             # Tensor [3, Hs, Ws]\n",
    "            \"input_boxes\":  input_boxes.to(torch.float32),            # Tensor [1, 4]\n",
    "            \"ground_truth_mask\": torch.as_tensor(mask, dtype=torch.float32)\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6f2c40f0824e44e19fdf9f98b63b4990",
      "46a45ba8db5f490aa08eb70730d34779",
      "a0c4fbab11e1464485a8e3da6b97f09f",
      "14816df0c2ae4721b5481e425b4d54fc",
      "370765abd2ed42e99f16f314ca9765c5",
      "d117ada3c17347ad93fe0b7119c36908",
      "61fd6f3e72fb4338b833a08d08cc7565",
      "40daacee80f146c6b56b252f8d500478",
      "5e20dd2934e244baa2791ba330b9dc65",
      "66a2c457e7f34cc0b32de3f7a3ffc132",
      "405c947cacc84b51996195ce1e6d528f",
      "48cf6d7b842349adb2778dbf4a0de887",
      "b72c383ac7194008ad75331cacf4d5db",
      "139084b9f2004a68958d7c1fe9baeb3a",
      "7e422fb571f64626ac26473219484fe5",
      "9be7fe598d2043399fcda0bfa0c032c3",
      "a5dfc291c5644289ad277ab404e33b84",
      "405c380e43e64da2ac8bbb042bb5efa1",
      "e9b4fe8059d040bda45a8e74e903425c",
      "9d666e28e99944b2a12e444722ff9d07",
      "5326f8791e89460c87e9b64a7fc7fd96",
      "69abb9b5f97c41048d229e87ead11990",
      "03f1eaeabd1346c99d96b0cd40ec6a06",
      "f88e1df1a7d548cbbb1f451145566f37",
      "c276d04a3ef645cb8dbca1809348cd4e",
      "dffd75bd9b87447aaf4b6871157ac853",
      "ac3b8eadb8e64a5cb11ddde1f556aac6",
      "d6308f9c098a45109dbcf2d54dd68f6e",
      "270bc9c222274b51abc69e9282c1f35c",
      "aff42317ae354ffbb8ac914a73a70a06",
      "377937ab5fd6405abaea39141127b780",
      "70aa3deaa81347b38a6788a446f05e35",
      "e7cc8759c9a74db09d301d02bd91095e"
     ]
    },
    "id": "-xlvjJcy91Z3",
    "outputId": "62bc3c8f-f214-4ba6-ee10-36c21127aa48"
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader # If DataLoader fails to load in the top, it should get importet here\n",
    "\n",
    "# CUDA-Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"üîå Nutzt Ger√§t:\", device)\n",
    "\n",
    "# modell and processor\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\") # sam_vit_large/huge kcould improve the result\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n",
    "\n",
    "# freeze Encoder\n",
    "for name, param in model.named_parameters(): # ensures that only gradients for the mask decoder are calculated\n",
    "    if name.startswith(\"vision_encoder\") or name.startswith(\"prompt_encoder\"):\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "# push data into gpu\n",
    "model.to(device) # attaches cuda-device to the model - model switches du CPU constantly otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbtRfIusOe8L"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Basis HF Datens√§tze beibehalten und nicht √ºberschreiben\n",
    "train_hf = train_dataset if not isinstance(train_dataset, SAMDatasetV2) else train_dataset.dataset\n",
    "val_hf   = val_dataset   if not isinstance(val_dataset,   SAMDatasetV2) else val_dataset.dataset\n",
    "\n",
    "# Wrapper einmalig anlegen\n",
    "train_sam = SAMDatasetV2(train_hf, processor, use_jitter=True)\n",
    "val_sam   = SAMDatasetV2(val_hf,   processor, use_jitter=True)\n",
    "\n",
    "# Zun√§chst ohne Nebenprozesse, damit keine alte Klassenversion in Subprozessen aktiv bleibt\n",
    "train_loader = DataLoader(train_sam, batch_size=2, shuffle=True,\n",
    "                          num_workers=0, pin_memory=True, persistent_workers=False)\n",
    "val_loader   = DataLoader(val_sam,   batch_size=2, shuffle=False,\n",
    "                          num_workers=0, pin_memory=True, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4r2fNvgEF5k"
   },
   "outputs": [],
   "source": [
    "# optimizer and loss\n",
    "# Note to self: Hyperparameter tuning to improve performance here\n",
    "optimizer = torch.optim.Adam(model.mask_decoder.parameters(), lr=1e-4)\n",
    "loss_fn = monai.losses.DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean') #uses DiceLoss as the loss function\n",
    "\n",
    "def dice_coeff(pred, gt, eps=1e-4):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    if pred.ndim == 3:  # [B,H,W] ‚Üí [B,1,H,W]\n",
    "        pred = pred.unsqueeze(1)\n",
    "    if gt.ndim == 3:\n",
    "        gt = gt.unsqueeze(1)\n",
    "    inter = (pred * gt).sum(dim=(1, 2, 3))\n",
    "    union = pred.sum(dim=(1, 2, 3)) + gt.sum(dim=(1, 2, 3))\n",
    "    return ((2 * inter + eps) / (union + eps)).mean().item()\n",
    "\n",
    "def iou(pred, gt, eps=1e-4):\n",
    "    pred = (torch.sigmoid(pred) > 0.5).float()\n",
    "    if pred.ndim == 3:\n",
    "        pred = pred.unsqueeze(1)\n",
    "    if gt.ndim == 3:\n",
    "        gt = gt.unsqueeze(1)\n",
    "    inter = (pred * gt).sum(dim=(1, 2, 3))\n",
    "    union = (pred + gt).sum(dim=(1, 2, 3)) - inter\n",
    "    return ((inter + eps) / (union + eps)).mean().item()\n",
    "\n",
    "# --- 6) History Container ---\n",
    "history = {\n",
    "    \"epoch\":  [],\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\":   [],\n",
    "    \"val_dice\":   [],\n",
    "    \"val_iou\":    [],\n",
    "    \"train_lr\":   [],\n",
    "    \"vepoch_time_sec\":     []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r2Nk1biHEMd2",
    "outputId": "83d20229-ad52-4f4f-fe95-b9db4cec6aeb"
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "# Gewichte der Epoche mit dem h√∂chsten Dice-Wert als Model speichern\n",
    "best_val_dice = 0.0\n",
    "\n",
    "# Training\n",
    "num_epochs = 20\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # um sicher zu gehen\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for batch in tqdm(train_loader):\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_boxes = batch[\"input_boxes\"].to(device)\n",
    "        masks = batch[\"ground_truth_mask\"].float().to(device)\n",
    "        #forward pass\n",
    "        outputs = model(pixel_values=pixel_values,\n",
    "                        input_boxes=input_boxes,\n",
    "                        multimask_output=False)\n",
    "        # compute loss\n",
    "        pred_masks = outputs.pred_masks.squeeze(1)\n",
    "        loss = loss_fn(pred_masks, masks.unsqueeze(1))\n",
    "\n",
    "        # backward pass (compute gradients of parameters w.r.t. loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_losses, val_dice_scores, val_iou_scores = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            input_boxes = batch[\"input_boxes\"].to(device)\n",
    "            masks = batch[\"ground_truth_mask\"].float().to(device)\n",
    "\n",
    "            outputs = model(pixel_values=pixel_values,\n",
    "                            input_boxes=input_boxes,\n",
    "                            multimask_output=False)\n",
    "\n",
    "            pred_masks = outputs.pred_masks.squeeze(1)\n",
    "\n",
    "            val_losses.append(loss_fn(pred_masks, masks.unsqueeze(1)).item())\n",
    "            val_dice_scores.append(dice_coeff(pred_masks, masks.unsqueeze(1)))\n",
    "            val_iou_scores.append(iou(pred_masks, masks.unsqueeze(1)))\n",
    "\n",
    "    lr_now = optimizer.param_groups[0]['lr']\n",
    "    if device == \"cuda\":\n",
    "      torch.cuda.synchronize()\n",
    "    t_epoch = time.perf_counter() - t0\n",
    "\n",
    "    history[\"epoch\"].append(epoch)\n",
    "    history[\"train_loss\"].append(mean(train_losses))\n",
    "    history[\"val_loss\"].append(mean(val_losses))\n",
    "    history[\"val_dice\"].append(mean(val_dice_scores))\n",
    "    history[\"val_iou\"].append(mean(val_iou_scores))\n",
    "    history[\"train_lr\"].append(lr_now)\n",
    "    history[\"vepoch_time_sec\"].append(t_epoch)\n",
    "\n",
    "     # Modell speichern, falls val_dice verbessert wurde\n",
    "    if history[\"val_dice\"][-1] > best_val_dice:\n",
    "        best_val_dice = history[\"val_dice\"][-1]\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")# Modell speichern\n",
    "        best_model_save_path = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/models/best_model_boxpromt_jitter_20ep_1e4.pt\"\n",
    "        torch.save(model.state_dict(), best_model_save_path)\n",
    "\n",
    "    print(\n",
    "      f\"Ep {epoch} ‚Äì Train L:{history['train_loss'][-1]:.4f} | \"\n",
    "      f\"Val L:{history['val_loss'][-1]:.4f} | \"\n",
    "      f\"Dice:{history['val_dice'][-1]:.4f} | \"\n",
    "      f\"IoU:{history['val_iou'][-1]:.4f}\"\n",
    "      )\n",
    "\n",
    "# save History as a Dataframe\n",
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_07_09/1e4/training_history_original.csv\"\n",
    "\n",
    "df_history.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Training-History gespeichert unter: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FI1KQ15Uo3Te",
    "outputId": "d3078273-00d1-4658-ee9d-e14fbfa10d70"
   },
   "outputs": [],
   "source": [
    "# save History as a Dataframe\n",
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "save_path = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_05_09/training_history_original_1e4.csv\"\n",
    "\n",
    "df_history.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Training-History gespeichert unter: {save_path}\")\n",
    "\n",
    "# Save the trained weights\n",
    "save_path = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/models/sam_finetuned_jitterBoxes_DiceCE_20ep_lr_1e4.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(\"‚úÖ Modell gespeichert unter:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wYYAzGKZ1RMQ",
    "outputId": "ca3f8ce5-9637-4f2c-f152-e38a6d41c564"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# Sicherstellen, dass der Zielordner existiert\n",
    "save_dir = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_07_09/1e-4\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Anzeige des DataFrames (falls noch nicht geladen: z.‚ÄØB. df_combined = pd.read_csv(...))\n",
    "display(df_history)\n",
    "\n",
    "# Plot: Loss-Verlauf\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(df_history['train_loss'], marker='o', label='Train Loss')\n",
    "plt.plot(df_history['val_loss'], marker='o', label='Val Loss')\n",
    "plt.title('Loss-Verlauf')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "loss_plot_path = os.path.join(save_dir, \"loss_plot_jitter.png\")\n",
    "plt.savefig(loss_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot: Validationsmetriken\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(df_history['val_dice'], marker='o', label='Val Dice')\n",
    "plt.plot(df_history['val_iou'], marker='o', label='Val IoU')\n",
    "plt.title('Validationsmetriken')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "metrics_plot_path = os.path.join(save_dir, \"metrics_plot_jitter.png\")\n",
    "plt.savefig(metrics_plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Plots gespeichert unter:\\n‚Üí {loss_plot_path}\\n‚Üí {metrics_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB5SG-46onxP"
   },
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "5JqkTtsVg2XV",
    "outputId": "b1a08616-1e28-4d97-d4ec-1507d5693a60"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebqcqTG2osFF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import tifffile\n",
    "import patchify\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import SamModel, SamConfig, SamProcessor\n",
    "\n",
    "best_model_save_path = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_07_09/1e-5/best_model_boxpromt_jitter_20ep.pt\"\n",
    "\n",
    "image_folder     = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/test_data/images\"     # .tif\n",
    "tps_mask_folder  = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/test_data/tps_layer\"  # .png (ROI/TPS)\n",
    "gt_folder        = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/test_data/gt_masks\"   # .png (GT f√ºr HA)\n",
    "out_folder       = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_08_09/Test/SAM\"\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "#out_folder       = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_08_09/Test/MY_HA\"\n",
    "#os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "# Masken und Geometrie\n",
    "def invert_mask(path: str) -> Tuple[np.ndarray, List[np.ndarray]]:\n",
    "    mask_orig = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask_orig is None:\n",
    "        raise FileNotFoundError(f\"Maske nicht gefunden: {path}\")\n",
    "    contour_TPS, _ = cv2.findContours(mask_orig, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.ones_like(mask_orig, dtype=np.uint8) * 255\n",
    "    cv2.drawContours(mask, contour_TPS, -1, 0, thickness=cv2.FILLED)\n",
    "    return mask, contour_TPS\n",
    "\n",
    "def apply_mask(img: np.ndarray, mask: np.ndarray, mode: str = \"and\") -> np.ndarray:\n",
    "    if mode == \"and\": return cv2.bitwise_and(img, img, mask=mask)\n",
    "    if mode == \"or\":  return cv2.bitwise_or(img, mask)\n",
    "    raise ValueError(\"apply_mask: mode muss 'and' oder 'or' sein\")\n",
    "\n",
    "def shift_mask_binary(m: np.ndarray, dx: int, dy: int) -> np.ndarray:\n",
    "    h, w = m.shape\n",
    "    out = np.zeros_like(m)\n",
    "    # Zielbereich im Ausgabebild\n",
    "    y0 = max(0,  dy);  y1 = min(h, h + dy)\n",
    "    x0 = max(0,  dx);  x1 = min(w, w + dx)\n",
    "    # Quellbereich im Eingabebild\n",
    "    yy0 = max(0, -dy); yy1 = yy0 + (y1 - y0)\n",
    "    xx0 = max(0, -dx); xx1 = xx0 + (x1 - x0)\n",
    "    if y1 > y0 and x1 > x0:\n",
    "        out[y0:y1, x0:x1] = m[yy0:yy1, xx0:xx1]\n",
    "    return out\n",
    "\n",
    "def pad_to_multiple(a: np.ndarray, multiple: int) -> np.ndarray:\n",
    "    H, W = a.shape[:2]\n",
    "    padH = (multiple - (H % multiple)) % multiple\n",
    "    padW = (multiple - (W % multiple)) % multiple\n",
    "    if padH or padW:\n",
    "        pads = ((0, padH), (0, padW)) + ((0, 0),) * (a.ndim - 2)\n",
    "        a = np.pad(a, pads, mode=\"constant\", constant_values=0)\n",
    "    return a\n",
    "\n",
    "def ceil_to_multiple(n: int, m: int) -> int:\n",
    "    return ((n + m - 1) // m) * m\n",
    "\n",
    "def mask_to_box(mask: np.ndarray, margin: int = 4, min_pixels: int = 1):\n",
    "    assert mask.ndim == 2\n",
    "    H, W = mask.shape\n",
    "    ys, xs = np.where(mask > 0)\n",
    "    if ys.size < min_pixels:\n",
    "        return None\n",
    "    y0, y1 = int(ys.min()), int(ys.max())\n",
    "    x0, x1 = int(xs.min()), int(xs.max())\n",
    "    if margin > 0:\n",
    "        y0 = max(0, y0 - margin)\n",
    "        x0 = max(0, x0 - margin)\n",
    "        y1 = min(H - 1, y1 + margin)\n",
    "        x1 = min(W - 1, x1 + margin)\n",
    "    return float(x0), float(y0), float(x1), float(y1)\n",
    "\n",
    "\n",
    "def make_cosine_window(p: int, eps: float = 1e-3) -> np.ndarray:\n",
    "\n",
    "    w1 = np.hanning(p).astype(np.float32)\n",
    "    w2 = np.outer(w1, w1).astype(np.float32)\n",
    "    return np.maximum(w2, eps)\n",
    "\n",
    "def reconstruct_overlapping(patches: np.ndarray,\n",
    "                            coords: np.ndarray,\n",
    "                            H_pad: int,\n",
    "                            W_pad: int,\n",
    "                            patch_size: int,\n",
    "                            window: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    acc  = np.zeros((H_pad, W_pad), dtype=np.float32)\n",
    "    wsum = np.zeros((H_pad, W_pad), dtype=np.float32)\n",
    "    for patch, (y0, x0) in zip(patches, coords):\n",
    "        y1 = y0 + patch_size\n",
    "        x1 = x0 + patch_size\n",
    "        acc[y0:y1, x0:x1]  += patch.astype(np.float32) * window\n",
    "        wsum[y0:y1, x0:x1] += window\n",
    "    return acc / np.maximum(wsum, 1e-6)\n",
    "\n",
    "def reconstruct_overlapping_binary(patches: np.ndarray,\n",
    "                                   coords: np.ndarray,\n",
    "                                   H_pad: int,\n",
    "                                   W_pad: int,\n",
    "                                   patch_size: int) -> np.ndarray:\n",
    "    acc = np.zeros((H_pad, W_pad), dtype=np.uint8)\n",
    "    for patch, (y0, x0) in zip(patches, coords):\n",
    "        y1 = y0 + patch_size\n",
    "        x1 = x0 + patch_size\n",
    "        cur = acc[y0:y1, x0:x1]\n",
    "        np.maximum(cur, patch, out=cur)\n",
    "        acc[y0:y1, x0:x1] = cur\n",
    "    return acc\n",
    "\n",
    "def thickness_per_column(binary_mask_0_255: np.ndarray) -> np.ndarray:\n",
    "    return np.sum(binary_mask_0_255 == 255, axis=0).astype(np.int32)\n",
    "\n",
    "def dice_iou(pred_0_255: np.ndarray, gt_0_255: np.ndarray) -> Tuple[float, float]:\n",
    "    p = (pred_0_255 > 0).astype(np.uint8)\n",
    "    g = (gt_0_255   > 0).astype(np.uint8)\n",
    "    inter = np.sum((p == 1) & (g == 1))\n",
    "    p_sum = np.sum(p)\n",
    "    g_sum = np.sum(g)\n",
    "    union = p_sum + g_sum - inter\n",
    "    dice = (2.0 * inter) / (p_sum + g_sum) if (p_sum + g_sum) > 0 else 1.0\n",
    "    iou  = (inter / union) if union > 0 else 1.0\n",
    "    return float(dice), float(iou)\n",
    "\n",
    "def coverage_recall(pred_0_255: np.ndarray, gt_0_255: np.ndarray) -> float:\n",
    "    p = (pred_0_255 > 0)\n",
    "    g = (gt_0_255   > 0)\n",
    "    gt_pos = np.sum(g)\n",
    "    if gt_pos == 0:\n",
    "        return 1.0 if np.sum(p) == 0 else 0.0\n",
    "    return float(np.sum(p & g) / gt_pos)\n",
    "\n",
    "def basename_noext(p: str) -> str:\n",
    "    return os.path.splitext(os.path.basename(p))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3DqB7fgR9R9U",
    "outputId": "c259ecc1-df02-4bb4-f745-c05360aa5705"
   },
   "outputs": [],
   "source": [
    "\n",
    "### SAM TRAINIERT ###\n",
    "\n",
    "model_config = SamConfig.from_pretrained(\"facebook/sam-vit-base\")\n",
    "processor    = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "my_HA_model  = SamModel(config=model_config)\n",
    "my_HA_model.load_state_dict(torch.load(best_model_save_path))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "my_HA_model.to(device)\n",
    "my_HA_model.eval()\n",
    "\n",
    "'''\n",
    "### SAM UNTRAINIERT ###\n",
    "model_name = \"facebook/sam-vit-base\"\n",
    "# Processor und Standard SAM laden\n",
    "processor = SamProcessor.from_pretrained(model_name)\n",
    "sam_model = SamModel.from_pretrained(model_name)\n",
    "# Ger√§t w√§hlen und Modell in den Auswertungsmodus setzen\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam_model.to(device)\n",
    "sam_model.eval()\n",
    "'''\n",
    "\n",
    "# PARAMETER\n",
    "\n",
    "patch_size = 256\n",
    "step       = 128\n",
    "final_thr  = 0.80\n",
    "save_viz   = True\n",
    "shift_px   = 110          # Verschiebung in Pixel nach oben f√ºr HA-Streifen\n",
    "margin    = 4            # Box-Rand in Pixel (Puffer rund um die eigentliche Box)\n",
    "min_px    = 1            # Minimale Pixelanzahl f√ºr eine Box\n",
    "\n",
    "\n",
    "\n",
    "# PAIRING\n",
    "# Bild <-> TPS-Schicht <-> Ground Truth\n",
    "\n",
    "imgs  = sorted(glob.glob(os.path.join(image_folder, \"*.tif\")))\n",
    "tps   = sorted(glob.glob(os.path.join(tps_mask_folder, \"*.png\")))\n",
    "gts   = sorted(glob.glob(os.path.join(gt_folder, \"*.png\")))\n",
    "\n",
    "img_map = {basename_noext(p): p for p in imgs}\n",
    "tps_map = {basename_noext(p): p for p in tps}\n",
    "gt_map  = {basename_noext(p): p for p in gts}\n",
    "\n",
    "common = sorted(set(img_map) & set(tps_map) & set(gt_map))\n",
    "pairs = [(img_map[k], tps_map[k], gt_map[k]) for k in common]\n",
    "print(f\"Gefundene Tripel: {len(pairs)}\")\n",
    "\n",
    "# PROCESSING\n",
    "\n",
    "win = make_cosine_window(patch_size)\n",
    "\n",
    "for idx, (img_path, tps_path, gt_path) in enumerate(pairs, 1):\n",
    "    stem = basename_noext(img_path)\n",
    "    print(f\"[{idx}/{len(pairs)}] {stem}\")\n",
    "    t0 = time.perf_counter()\n",
    "    try:\n",
    "        # Laden\n",
    "        large_img = tifffile.imread(img_path)\n",
    "        if large_img is None or large_img.ndim != 2:\n",
    "            raise ValueError(\"Erwarte zweidimensionales Graubild\")\n",
    "\n",
    "        tps_inv, _ = invert_mask(tps_path)            # 255 au√üerhalb TPS\n",
    "        img_masked = apply_mask(large_img, tps_inv)   # Bild auf TPS begrenzen\n",
    "\n",
    "        gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if gt is None:\n",
    "            raise FileNotFoundError(f\"GT nicht gefunden: {gt_path}\")\n",
    "        gt_bin = (gt > 0).astype(np.uint8) * 255\n",
    "        gt_masked = cv2.bitwise_and(gt_bin, tps_inv)  # GT auf TPS begrenzen\n",
    "\n",
    "        # HA Streifen aus verschobener Nullregion erzeugen\n",
    "        zero_mask = (img_masked == 0).astype(np.uint8) * 255\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        zero_mask = cv2.morphologyEx(zero_mask, cv2.MORPH_OPEN, kernel)\n",
    "        m_orig  = (zero_mask > 0).astype(np.uint8)\n",
    "        m_shift = shift_mask_binary(m_orig, dx=0, dy=-shift_px)\n",
    "        ha_mask = ((m_shift == 1) & (m_orig == 0)).astype(np.uint8) * 255\n",
    "\n",
    "        # Patch Bildung\n",
    "        assert img_masked.shape == gt_masked.shape == ha_mask.shape\n",
    "        H_orig, W_orig = img_masked.shape\n",
    "        img_pad = pad_to_multiple(img_masked, patch_size)\n",
    "        gt_pad  = pad_to_multiple(gt_masked,  patch_size)\n",
    "        ha_pad  = pad_to_multiple(ha_mask,    patch_size)\n",
    "\n",
    "        img_p = patchify.patchify(img_pad, (patch_size, patch_size), step=step)\n",
    "        gt_p  = patchify.patchify(gt_pad,  (patch_size, patch_size), step=step)\n",
    "        ha_p  = patchify.patchify(ha_pad,  (patch_size, patch_size), step=step)\n",
    "\n",
    "        img_patches, gt_patches, ha_patches, coords = [], [], [], []\n",
    "        for i in range(img_p.shape[0]):\n",
    "            for j in range(img_p.shape[1]):\n",
    "                y0 = i * step\n",
    "                x0 = j * step\n",
    "                img_patches.append(img_p[i, j])\n",
    "                gt_patches.append(gt_p[i, j].astype(np.uint8))\n",
    "                ha_patches.append(ha_p[i, j].astype(np.uint8))\n",
    "                coords.append((y0, x0))\n",
    "        img_patches = np.array(img_patches)\n",
    "        gt_patches  = np.array(gt_patches)\n",
    "        ha_patches  = np.array(ha_patches)\n",
    "        coords      = np.array(coords, dtype=np.int32)\n",
    "\n",
    "        # Inferenz mit SAM Standard und HA Box\n",
    "        N, H, W = img_patches.shape\n",
    "        probs = np.zeros((N, H, W), dtype=np.float32)\n",
    "\n",
    "        prompt_log = {\n",
    "            \"promptart\": \"box\",\n",
    "            \"quelle\": \"ha\",\n",
    "            \"parameter\": {\"margin\": margin, \"min_pixels\": min_px,\n",
    "                          \"patch_size\": patch_size, \"step\": step,\n",
    "                          \"shift_px\": shift_px},\n",
    "            \"prompts\": []\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for k in range(N):\n",
    "                img_patch = img_patches[k]\n",
    "                ha_patch  = ha_patches[k]\n",
    "\n",
    "                box = mask_to_box(ha_patch, margin=margin, min_pixels=min_px)\n",
    "\n",
    "                # Fallback Box wenn keine Region gefunden wurde\n",
    "                if box is None:\n",
    "                    h, w = img_patch.shape\n",
    "                    cy = max(0, min(h - 1, h // 2))\n",
    "                    band = 2\n",
    "                    y0b = max(0, cy - band)\n",
    "                    y1b = min(h - 1, cy + band)\n",
    "                    box = [0, y0b, w - 1, y1b]\n",
    "\n",
    "                x0, y0, x1, y1 = box\n",
    "                pil_img = Image.fromarray(img_patch).convert(\"RGB\")\n",
    "\n",
    "                inputs = processor(\n",
    "                    images=pil_img,\n",
    "                    input_boxes=[[[x0, y0, x1, y1]]],\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                inputs = {kk: vv.to(device) for kk, vv in inputs.items()}\n",
    "\n",
    "                #out = sam_model(**inputs, multimask_output=False) # F√ºr untrainierten SAM\n",
    "                out = my_HA_model(**inputs, multimask_output=False) # F√ºr trainierten SAM\n",
    "                p_map = torch.sigmoid(out.pred_masks[0, 0, 0])  # Form H mal W\n",
    "                probs[k] = p_map.cpu().numpy()\n",
    "\n",
    "                gy, gx = int(coords[k][0]), int(coords[k][1])\n",
    "                box_global = [float(x0 + gx), float(y0 + gy), float(x1 + gx), float(y1 + gy)]\n",
    "                prompt_log[\"prompts\"].append({\n",
    "                    \"patch_index\": int(k),\n",
    "                    \"patch_top_left\": [gy, gx],\n",
    "                    \"box_global_xyxy\": box_global\n",
    "                })\n",
    "\n",
    "        # Rekonstruktion\n",
    "        H_pad = ceil_to_multiple(H_orig, patch_size)\n",
    "        W_pad = ceil_to_multiple(W_orig, patch_size)\n",
    "\n",
    "        full_prob = reconstruct_overlapping(probs, coords, H_pad, W_pad, patch_size, win)\n",
    "        full_pred = (full_prob > final_thr).astype(np.uint8) * 255\n",
    "        full_img  = reconstruct_overlapping(img_patches.astype(np.float32), coords, H_pad, W_pad, patch_size, win)\n",
    "        full_gt   = reconstruct_overlapping_binary(gt_patches, coords, H_pad, W_pad, patch_size)\n",
    "\n",
    "        # Zuschnitt auf Originalma√ü\n",
    "        full_img_c  = full_img[:H_orig, :W_orig]\n",
    "        full_prob_c = full_prob[:H_orig, :W_orig]\n",
    "        full_pred_c = full_pred[:H_orig, :W_orig]\n",
    "        full_gt_c   = full_gt[:H_orig, :W_orig]\n",
    "\n",
    "        # Artefakte speichern\n",
    "        prob_u8 = np.rint(np.clip(full_prob_c * 255.0, 0, 255)).astype(np.uint8)\n",
    "        prob_dir = os.path.join(out_folder, \"prob_maps\")\n",
    "        os.makedirs(prob_dir, exist_ok=True)\n",
    "        out_prob = os.path.join(prob_dir, f\"{stem}_prob.png\")\n",
    "\n",
    "        pred_dir = os.path.join(out_folder, \"pred_masks\")\n",
    "        os.makedirs(pred_dir, exist_ok=True)\n",
    "        out_pred = os.path.join(pred_dir, f\"{stem}_pred.png\")\n",
    "\n",
    "        gt_dir = os.path.join(out_folder, \"gt_mask\")\n",
    "        os.makedirs(gt_dir, exist_ok=True)\n",
    "        out_gt = os.path.join(gt_dir, f\"{stem}_gt.png\")\n",
    "\n",
    "        cv2.imwrite(out_prob, prob_u8)\n",
    "        cv2.imwrite(out_pred, full_pred_c)\n",
    "        cv2.imwrite(out_gt,   full_gt_c)\n",
    "\n",
    "        # Dickenprofile\n",
    "        th_pred = thickness_per_column(full_pred_c)\n",
    "        th_gt   = thickness_per_column(full_gt_c)\n",
    "\n",
    "        thickness_pred_dir = os.path.join(out_folder, \"thickness_pred\")\n",
    "        os.makedirs(thickness_pred_dir, exist_ok=True)\n",
    "        out_th_pred = os.path.join(thickness_pred_dir, f\"{stem}_thickness_pred.csv\")\n",
    "\n",
    "        thickness_gt_dir = os.path.join(out_folder, \"thickness_gt\")\n",
    "        os.makedirs(thickness_gt_dir, exist_ok=True)\n",
    "        out_th_gt   = os.path.join(thickness_gt_dir, f\"{stem}_thickness_gt.csv\")\n",
    "\n",
    "        idxs = np.arange(W_orig, dtype=np.int32)\n",
    "        np.savetxt(out_th_pred, np.c_[idxs, th_pred], delimiter=\",\",\n",
    "                   header=\"spaltenindex,dicke_pixel\", fmt=\"%d\", comments=\"\")\n",
    "        np.savetxt(out_th_gt,   np.c_[idxs, th_gt],   delimiter=\",\",\n",
    "                   header=\"spaltenindex,dicke_pixel\", fmt=\"%d\", comments=\"\")\n",
    "\n",
    "        # Bildmetriken\n",
    "        dice, iou = dice_iou(full_pred_c, full_gt_c)\n",
    "        diff = th_pred.astype(np.int32) - th_gt.astype(np.int32)\n",
    "        mae  = float(np.mean(np.abs(diff))) if diff.size else 0.0\n",
    "        bias = float(np.mean(diff)) if diff.size else 0.0\n",
    "        mabs = int(np.max(np.abs(diff))) if diff.size else 0\n",
    "        cover = coverage_recall(full_pred_c, full_gt_c)\n",
    "        t_ms = (time.perf_counter() - t0) * 1000.0\n",
    "\n",
    "        metrics_dir = os.path.join(out_folder, \"metrics\")\n",
    "        os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "        metrics = {\n",
    "            \"dice\": dice,\n",
    "            \"iou\": iou,\n",
    "            \"mae_dicke\": mae,\n",
    "            \"bias_dicke\": bias,\n",
    "            \"max_abs_err\": mabs,\n",
    "            \"abdeckung\": cover,\n",
    "            \"laufzeit_ms\": float(round(t_ms, 1))\n",
    "        }\n",
    "        with open(os.path.join(metrics_dir, f\"{stem}_metrics.json\"), \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "\n",
    "        # Prompt Protokoll\n",
    "        prompts_dir = os.path.join(out_folder, \"prompts\")\n",
    "        os.makedirs(prompts_dir, exist_ok=True)\n",
    "        with open(os.path.join(prompts_dir, f\"{stem}_prompt_protokoll.json\"), \"w\") as f:\n",
    "            json.dump(prompt_log, f, indent=2)\n",
    "\n",
    "        # Bildmetadaten\n",
    "        metadata_dir = os.path.join(out_folder, \"metadata\")\n",
    "        os.makedirs(metadata_dir, exist_ok=True)\n",
    "        metadata = {\n",
    "            \"bildkennung\": stem,\n",
    "            \"patchgroesse\": int(patch_size),\n",
    "            \"schrittweite\": int(step),\n",
    "            \"ueberlappung\": float(step / patch_size),\n",
    "            \"schwellenwert\": float(final_thr),\n",
    "            \"verwendete_nachbearbeitung\": \"keine\",\n",
    "            \"prompt_quelle\": \"ha\",\n",
    "            \"ha_shift_px\": int(shift_px),\n",
    "            \"blending\": \"cosine_window_hanning_eps1e-3\",\n",
    "            \"prob_map_skalierung\": \"round(prob*255)\"\n",
    "        }\n",
    "        with open(os.path.join(metadata_dir, f\"{stem}_bildmetadaten.json\"), \"w\") as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "\n",
    "        # Visualisierung\n",
    "        if save_viz:\n",
    "            viz_dir = os.path.join(out_folder, \"viz\")\n",
    "            os.makedirs(viz_dir, exist_ok=True)\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "            axes[0].imshow(full_img_c, cmap=\"gray\"); axes[0].set_title(\"Bild\"); axes[0].axis(\"off\")\n",
    "            axes[1].imshow(full_gt_c, cmap=\"gray\");  axes[1].set_title(\"GT\"); axes[1].axis(\"off\")\n",
    "            axes[2].imshow(prob_u8, vmin=0, vmax=255); axes[2].set_title(\"Wahrscheinlichkeit\"); axes[2].axis(\"off\")\n",
    "            axes[3].imshow(full_pred_c, cmap=\"gray\"); axes[3].set_title(\"Vorhersage\"); axes[3].axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(viz_dir, f\"{stem}_viz.png\"), dpi=150)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"{stem}: prob, pred, profile und JSON gespeichert\")\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei {stem}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mBlUrJHZ2MWZ",
    "outputId": "c0c8139e-bd23-4f13-b2e4-092b8b82b953"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Wurzelordner anpassen, falls n√∂tig\n",
    "base_dir = Path(\"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_08_09/SAM/gt_mask\")\n",
    "\n",
    "pattern = re.compile(r\"_bin\\.png$\", re.IGNORECASE)\n",
    "\n",
    "renamed = 0\n",
    "skipped_exists = 0\n",
    "\n",
    "candidates = [p for p in base_dir.rglob(\"*.png\") if pattern.search(p.name)]\n",
    "print(f\"Gefundene Kandidaten: {len(candidates)}\")\n",
    "\n",
    "for p in candidates:\n",
    "    target = p.with_name(pattern.sub(\"_gt.png\", p.name))\n",
    "    if target.exists():\n",
    "        print(f\"√ºbersprungen, Ziel existiert bereits: {target}\")\n",
    "        skipped_exists += 1\n",
    "        continue\n",
    "    p.rename(target)\n",
    "    renamed += 1\n",
    "\n",
    "print(f\"Umbenannt: {renamed}\")\n",
    "print(f\"√úbersprungen wegen vorhandenem Ziel: {skipped_exists}\")\n",
    "print(\"Fertig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "Yhe4BAILsHiF",
    "outputId": "43bcfbbf-5010-4cd6-8725-186886253eec"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Pfade\n",
    "base_dir = Path(\"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_08_09/Test/SAM\")\n",
    "pred_dir = base_dir / \"thickness_pred\"\n",
    "gt_dir   = base_dir / \"thickness_gt\"\n",
    "\n",
    "# ---------- Helfer ----------\n",
    "\n",
    "def has_header(csv_path):\n",
    "    \"\"\"Erkennt simpel, ob die erste Zeile eher Header ist.\"\"\"\n",
    "    with open(csv_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        first = f.readline()\n",
    "    # Wenn Buchstaben in der ersten Zeile stecken, werten wir das als Header\n",
    "    return bool(re.search(r'[A-Za-z√Ñ√ñ√ú√§√∂√º]', first))\n",
    "\n",
    "def read_thickness_csv(csv_path):\n",
    "    \"\"\"Liest eine 2-Spalten-CSV: [spaltenindex, dicke_pixel]. Robust gegen Header und Dezimalkomma.\"\"\"\n",
    "    if has_header(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # versuche die wahrscheinlichsten Spaltennamen\n",
    "        cols = list(df.columns)\n",
    "        if len(cols) < 2:\n",
    "            # Fallback: ohne Header lesen\n",
    "            df = pd.read_csv(csv_path, header=None, names=[\"spaltenindex\", \"dicke_pixel\"])\n",
    "        else:\n",
    "            # mappe m√∂glichst auf Standardnamen\n",
    "            mapping = {}\n",
    "            # erstbeste zwei Spalten nehmen, aber sinnvoll benennen\n",
    "            mapping[cols[0]] = \"spaltenindex\"\n",
    "            mapping[cols[1]] = \"dicke_pixel\"\n",
    "            df = df.rename(columns=mapping)[[\"spaltenindex\", \"dicke_pixel\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path, header=None, names=[\"spaltenindex\", \"dicke_pixel\"])\n",
    "\n",
    "    # Dezimalkomma abfangen und auf float casten\n",
    "    for c in [\"spaltenindex\", \"dicke_pixel\"]:\n",
    "        ser = df[c].astype(str).str.replace(',', '.', regex=False)\n",
    "        df[c] = pd.to_numeric(ser, errors='coerce')\n",
    "\n",
    "    # sortieren, Duplikate im Index vermeiden\n",
    "    df = df.drop_duplicates(subset=[\"spaltenindex\"]).sort_values(\"spaltenindex\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def clean_stem(p: Path):\n",
    "    \"\"\"\n",
    "    Entfernt Suffixe wie _pred, _gt, _thickness_pred, _thickness_gt\n",
    "    sowie optionale Dateiendungen, liefert den gemeinsamen Stamm.\n",
    "    \"\"\"\n",
    "    stem = p.stem\n",
    "    # erst thickness Varianten\n",
    "    stem = re.sub(r'_(?:thickness_)?(pred|gt)$', '', stem, flags=re.IGNORECASE)\n",
    "    return stem\n",
    "\n",
    "def compute_metrics(errors: np.ndarray, total_cols: int):\n",
    "    \"\"\"\n",
    "    Gibt Kennwerte als Dict zur√ºck.\n",
    "    errors: 1D-Array der validen Fehler e(j) = d_pred - d_ref\n",
    "    total_cols: Gesamtzahl der Spalten (vor Filter), f√ºr Abdeckung\n",
    "    \"\"\"\n",
    "    W = int(np.sum(np.isfinite(errors)))\n",
    "    if W == 0:\n",
    "        return dict(W=0, total_columns=int(total_cols), coverage=np.nan,\n",
    "                    MAE=np.nan, Bias=np.nan, Std=np.nan,\n",
    "                    CI95_lower=np.nan, CI95_upper=np.nan,\n",
    "                    MaxAbsError=np.nan)\n",
    "\n",
    "    e = errors[np.isfinite(errors)]\n",
    "    mae = float(np.mean(np.abs(e)))\n",
    "    bias = float(np.mean(e))\n",
    "    std = float(np.std(e, ddof=1)) if W > 1 else np.nan\n",
    "\n",
    "    if W > 1 and np.isfinite(std):\n",
    "        tcrit = stats.t.ppf(0.975, df=W-1)\n",
    "        half_width = tcrit * std / math.sqrt(W)\n",
    "        ci_lo = bias - half_width\n",
    "        ci_hi = bias + half_width\n",
    "    else:\n",
    "        ci_lo = np.nan\n",
    "        ci_hi = np.nan\n",
    "\n",
    "    max_abs = float(np.max(np.abs(e)))\n",
    "    coverage = float(W / total_cols) if total_cols > 0 else np.nan\n",
    "\n",
    "    return dict(W=W, total_columns=int(total_cols), coverage=coverage,\n",
    "                MAE=mae, Bias=bias, Std=std,\n",
    "                CI95_lower=ci_lo, CI95_upper=ci_hi,\n",
    "                MaxAbsError=max_abs)\n",
    "\n",
    "# ---------- Dateien paaren ----------\n",
    "\n",
    "pred_files = list(pred_dir.glob(\"*.csv\"))\n",
    "gt_files   = list(gt_dir.glob(\"*.csv\"))\n",
    "\n",
    "pred_map = {clean_stem(p): p for p in pred_files}\n",
    "gt_map   = {clean_stem(p): p for p in gt_files}\n",
    "\n",
    "common_stems = sorted(set(pred_map.keys()) & set(gt_map.keys()))\n",
    "missing_pred = sorted(set(gt_map.keys()) - set(pred_map.keys()))\n",
    "missing_gt   = sorted(set(pred_map.keys()) - set(gt_map.keys()))\n",
    "\n",
    "if missing_pred:\n",
    "    print(\"Warnung: Es fehlen _pred Dateien f√ºr:\", missing_pred)\n",
    "if missing_gt:\n",
    "    print(\"Warnung: Es fehlen _gt Dateien f√ºr:\", missing_gt)\n",
    "\n",
    "# ---------- Metriken je Paar und gesamt ----------\n",
    "\n",
    "rows = []\n",
    "all_errors = []\n",
    "\n",
    "for stem in common_stems:\n",
    "    df_pred = read_thickness_csv(pred_map[stem]).rename(columns={\"dicke_pixel\": \"d_pred\"})\n",
    "    df_gt   = read_thickness_csv(gt_map[stem]).rename(columns={\"dicke_pixel\": \"d_ref\"})\n",
    "\n",
    "    # Outer-Join auf Spaltenindex, um Gesamtzahl der Spalten zu bestimmen\n",
    "    merged = pd.merge(df_pred[[\"spaltenindex\", \"d_pred\"]],\n",
    "                      df_gt[[\"spaltenindex\", \"d_ref\"]],\n",
    "                      on=\"spaltenindex\", how=\"outer\", sort=True)\n",
    "\n",
    "    # Gesamtzahl vor dem Filter\n",
    "    total_cols = merged[\"spaltenindex\"].nunique()\n",
    "\n",
    "    # valide Paare: beide Werte endlich\n",
    "    valid = merged[[\"d_pred\", \"d_ref\"]].apply(np.isfinite).all(axis=1)\n",
    "    merged_valid = merged.loc[valid].copy()\n",
    "\n",
    "    # Fehler\n",
    "    merged_valid[\"e\"] = merged_valid[\"d_pred\"] - merged_valid[\"d_ref\"]\n",
    "\n",
    "    # Kennwerte\n",
    "    metrics = compute_metrics(merged_valid[\"e\"].to_numpy(), total_cols)\n",
    "    metrics[\"datei_stamm\"] = stem\n",
    "    rows.append(metrics)\n",
    "\n",
    "    # f√ºr Gesamt\n",
    "    all_errors.append(merged_valid[\"e\"].to_numpy())\n",
    "\n",
    "# Gesamt √ºber alle Paare\n",
    "if all_errors:\n",
    "    all_errors_vec = np.concatenate(all_errors)\n",
    "    total_cols_sum = sum(r[\"total_columns\"] for r in rows)  # Summe der Spalten √ºber alle Dateien\n",
    "    overall = compute_metrics(all_errors_vec, total_cols_sum)\n",
    "    overall[\"datei_stamm\"] = \"ALLE_DATEIEN\"\n",
    "    rows.append(overall)\n",
    "\n",
    "# ---------- Ergebnis als Tabelle ----------\n",
    "\n",
    "cols_order = [\"datei_stamm\", \"W\", \"total_columns\", \"coverage\",\n",
    "              \"MAE\", \"Bias\", \"Std\", \"CI95_lower\", \"CI95_upper\", \"MaxAbsError\"]\n",
    "\n",
    "result_df = pd.DataFrame.from_records(rows)\n",
    "\n",
    "if result_df.empty:\n",
    "    print(\"Es wurden keine Paare ausgewertet. Pr√ºfe die Dateinamen in thickness_pred und thickness_gt.\")\n",
    "    result_df = pd.DataFrame(columns=cols_order)\n",
    "else:\n",
    "    # fehlende Spalten erg√§nzen, Reihenfolge erzwingen\n",
    "    for c in cols_order:\n",
    "        if c not in result_df:\n",
    "            result_df[c] = np.nan\n",
    "    result_df = result_df[cols_order]\n",
    "\n",
    "num_cols = [\"coverage\", \"MAE\", \"Bias\", \"Std\", \"CI95_lower\", \"CI95_upper\", \"MaxAbsError\"]\n",
    "for c in num_cols:\n",
    "    if c in result_df:\n",
    "        result_df[c] = result_df[c].astype(float).round(6)\n",
    "\n",
    "out_path = base_dir / \"thickness_metrics_summary_2.csv\"\n",
    "result_df.to_csv(out_path, index=False)\n",
    "print(f\"Fertig. Zusammenfassung gespeichert unter:\\n{out_path}\")\n",
    "display(result_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
