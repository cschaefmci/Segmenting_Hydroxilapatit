{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB5SG-46onxP"
   },
   "source": [
    "## Integration in den Prüfprozess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7E1KUC79yYb",
    "outputId": "c60f26ba-7b9c-4b27-df50-e550795900dd"
   },
   "outputs": [],
   "source": [
    "#to aquire full access to the data, connect the google drive folder to this Notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "5JqkTtsVg2XV",
    "outputId": "329e7f4f-f777-47d7-ab04-28dc8a244882"
   },
   "outputs": [],
   "source": [
    "!pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebqcqTG2osFF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import tifffile\n",
    "import patchify\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import SamModel, SamConfig, SamProcessor\n",
    "\n",
    "best_model_save_path = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_07_09/5e-5/best_model_boxpromt_jitter_20ep_5e5.pt\"\n",
    "\n",
    "image_folder     = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/validation_data/images\"     # .tif\n",
    "tps_mask_folder  = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/validation_data/tps_layer\"  # .png (ROI/TPS)\n",
    "gt_folder        = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/validation_data/gt_masks\"   # .png (GT für HA)\n",
    "out_folder       = \"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_07_09/5e5/inference\"\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "# Masken und Geometrie\n",
    "def invert_mask(path: str) -> Tuple[np.ndarray, List[np.ndarray]]:\n",
    "    mask_orig = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask_orig is None:\n",
    "        raise FileNotFoundError(f\"Maske nicht gefunden: {path}\")\n",
    "    contour_TPS, _ = cv2.findContours(mask_orig, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.ones_like(mask_orig, dtype=np.uint8) * 255\n",
    "    cv2.drawContours(mask, contour_TPS, -1, 0, thickness=cv2.FILLED)\n",
    "    return mask, contour_TPS\n",
    "\n",
    "def apply_mask(img: np.ndarray, mask: np.ndarray, mode: str = \"and\") -> np.ndarray:\n",
    "    if mode == \"and\": return cv2.bitwise_and(img, img, mask=mask)\n",
    "    if mode == \"or\":  return cv2.bitwise_or(img, mask)\n",
    "    raise ValueError(\"apply_mask: mode muss 'and' oder 'or' sein\")\n",
    "\n",
    "def shift_mask_binary(m: np.ndarray, dx: int, dy: int) -> np.ndarray:\n",
    "    h, w = m.shape\n",
    "    out = np.zeros_like(m)\n",
    "    # Zielbereich im Ausgabebild\n",
    "    y0 = max(0,  dy);  y1 = min(h, h + dy)\n",
    "    x0 = max(0,  dx);  x1 = min(w, w + dx)\n",
    "    # Quellbereich im Eingabebild\n",
    "    yy0 = max(0, -dy); yy1 = yy0 + (y1 - y0)\n",
    "    xx0 = max(0, -dx); xx1 = xx0 + (x1 - x0)\n",
    "    if y1 > y0 and x1 > x0:\n",
    "        out[y0:y1, x0:x1] = m[yy0:yy1, xx0:xx1]\n",
    "    return out\n",
    "\n",
    "def pad_to_multiple(a: np.ndarray, multiple: int) -> np.ndarray:\n",
    "    H, W = a.shape[:2]\n",
    "    padH = (multiple - (H % multiple)) % multiple\n",
    "    padW = (multiple - (W % multiple)) % multiple\n",
    "    if padH or padW:\n",
    "        pads = ((0, padH), (0, padW)) + ((0, 0),) * (a.ndim - 2)\n",
    "        a = np.pad(a, pads, mode=\"constant\", constant_values=0)\n",
    "    return a\n",
    "\n",
    "def ceil_to_multiple(n: int, m: int) -> int:\n",
    "    return ((n + m - 1) // m) * m\n",
    "\n",
    "def mask_to_box(mask: np.ndarray, margin: int = 4, min_pixels: int = 1):\n",
    "    assert mask.ndim == 2\n",
    "    H, W = mask.shape\n",
    "    ys, xs = np.where(mask > 0)\n",
    "    if ys.size < min_pixels:\n",
    "        return None\n",
    "    y0, y1 = int(ys.min()), int(ys.max())\n",
    "    x0, x1 = int(xs.min()), int(xs.max())\n",
    "    if margin > 0:\n",
    "        y0 = max(0, y0 - margin)\n",
    "        x0 = max(0, x0 - margin)\n",
    "        y1 = min(H - 1, y1 + margin)\n",
    "        x1 = min(W - 1, x1 + margin)\n",
    "    return float(x0), float(y0), float(x1), float(y1)\n",
    "\n",
    "\n",
    "def make_cosine_window(p: int, eps: float = 1e-3) -> np.ndarray:\n",
    "\n",
    "    w1 = np.hanning(p).astype(np.float32)\n",
    "    w2 = np.outer(w1, w1).astype(np.float32)\n",
    "    return np.maximum(w2, eps)\n",
    "\n",
    "def reconstruct_overlapping(patches: np.ndarray,\n",
    "                            coords: np.ndarray,\n",
    "                            H_pad: int,\n",
    "                            W_pad: int,\n",
    "                            patch_size: int,\n",
    "                            window: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    acc  = np.zeros((H_pad, W_pad), dtype=np.float32)\n",
    "    wsum = np.zeros((H_pad, W_pad), dtype=np.float32)\n",
    "    for patch, (y0, x0) in zip(patches, coords):\n",
    "        y1 = y0 + patch_size\n",
    "        x1 = x0 + patch_size\n",
    "        acc[y0:y1, x0:x1]  += patch.astype(np.float32) * window\n",
    "        wsum[y0:y1, x0:x1] += window\n",
    "    return acc / np.maximum(wsum, 1e-6)\n",
    "\n",
    "def reconstruct_overlapping_binary(patches: np.ndarray,\n",
    "                                   coords: np.ndarray,\n",
    "                                   H_pad: int,\n",
    "                                   W_pad: int,\n",
    "                                   patch_size: int) -> np.ndarray:\n",
    "    acc = np.zeros((H_pad, W_pad), dtype=np.uint8)\n",
    "    for patch, (y0, x0) in zip(patches, coords):\n",
    "        y1 = y0 + patch_size\n",
    "        x1 = x0 + patch_size\n",
    "        cur = acc[y0:y1, x0:x1]\n",
    "        np.maximum(cur, patch, out=cur)\n",
    "        acc[y0:y1, x0:x1] = cur\n",
    "    return acc\n",
    "\n",
    "def thickness_per_column(binary_mask_0_255: np.ndarray) -> np.ndarray:\n",
    "    return np.sum(binary_mask_0_255 == 255, axis=0).astype(np.int32)\n",
    "\n",
    "def dice_iou(pred_0_255: np.ndarray, gt_0_255: np.ndarray) -> Tuple[float, float]:\n",
    "    p = (pred_0_255 > 0).astype(np.uint8)\n",
    "    g = (gt_0_255   > 0).astype(np.uint8)\n",
    "    inter = np.sum((p == 1) & (g == 1))\n",
    "    p_sum = np.sum(p)\n",
    "    g_sum = np.sum(g)\n",
    "    union = p_sum + g_sum - inter\n",
    "    dice = (2.0 * inter) / (p_sum + g_sum) if (p_sum + g_sum) > 0 else 1.0\n",
    "    iou  = (inter / union) if union > 0 else 1.0\n",
    "    return float(dice), float(iou)\n",
    "\n",
    "def coverage_recall(pred_0_255: np.ndarray, gt_0_255: np.ndarray) -> float:\n",
    "    p = (pred_0_255 > 0)\n",
    "    g = (gt_0_255   > 0)\n",
    "    gt_pos = np.sum(g)\n",
    "    if gt_pos == 0:\n",
    "        return 1.0 if np.sum(p) == 0 else 0.0\n",
    "    return float(np.sum(p & g) / gt_pos)\n",
    "\n",
    "def basename_noext(p: str) -> str:\n",
    "    return os.path.splitext(os.path.basename(p))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833,
     "referenced_widgets": [
      "ddcfa7e197bd4197958c91090c8fac77",
      "1f6422f0f7574f329d342096bcacff4a",
      "07a82d629a9648a69030c2f33324035d",
      "a358c607fec745a8b6a9cd8cbbaf5180",
      "fe0b237df5b6467a9e59d4181fc8bb7d",
      "09aae2514d0c46ad91c0800e27a08a31",
      "c2a26ead73864764bef9465d7daffdbf",
      "b138021b9a30468abc74c9195a7944a6",
      "d5dc33e73b0948f6a67330b3e22e8bee",
      "a49aafe9b039463d9078bbd77ddebdfe",
      "0c4a19bb0c95418984dd6a96e2147f89"
     ]
    },
    "id": "3wBO7NHaqi7U",
    "outputId": "07630a18-4748-4578-d6ec-2af5ca6098dd"
   },
   "outputs": [],
   "source": [
    "### SAM TRAINIERT ###\n",
    "\n",
    "model_config = SamConfig.from_pretrained(\"facebook/sam-vit-base\")\n",
    "processor    = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "my_HA_model  = SamModel(config=model_config)\n",
    "my_HA_model.load_state_dict(torch.load(best_model_save_path))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "my_HA_model.to(device)\n",
    "my_HA_model.eval()\n",
    "\n",
    "'''\n",
    "### SAM UNTRAINIERT ###\n",
    "model_name = \"facebook/sam-vit-base\"\n",
    "# Processor und Standard SAM laden\n",
    "processor = SamProcessor.from_pretrained(model_name)\n",
    "sam_model = SamModel.from_pretrained(model_name)\n",
    "# Gerät wählen und Modell in den Auswertungsmodus setzen\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sam_model.to(device)\n",
    "sam_model.eval()\n",
    "'''\n",
    "\n",
    "# PARAMETER\n",
    "\n",
    "patch_size = 256\n",
    "step       = 128\n",
    "final_thr  = 0.80\n",
    "save_viz   = True\n",
    "shift_px   = 110          # Verschiebung in Pixel nach oben für HA-Streifen\n",
    "margin    = 4            # Box-Rand in Pixel (Puffer rund um die eigentliche Box)\n",
    "min_px    = 1            # Minimale Pixelanzahl für eine Box\n",
    "\n",
    "\n",
    "\n",
    "# PAIRING\n",
    "# Bild <-> TPS-Schicht <-> Ground Truth\n",
    "\n",
    "imgs  = sorted(glob.glob(os.path.join(image_folder, \"*.tif\")))\n",
    "tps   = sorted(glob.glob(os.path.join(tps_mask_folder, \"*.png\")))\n",
    "gts   = sorted(glob.glob(os.path.join(gt_folder, \"*.png\")))\n",
    "\n",
    "img_map = {basename_noext(p): p for p in imgs}\n",
    "tps_map = {basename_noext(p): p for p in tps}\n",
    "gt_map  = {basename_noext(p): p for p in gts}\n",
    "\n",
    "common = sorted(set(img_map) & set(tps_map) & set(gt_map))\n",
    "pairs = [(img_map[k], tps_map[k], gt_map[k]) for k in common]\n",
    "print(f\"Gefundene Tripel: {len(pairs)}\")\n",
    "\n",
    "# PROCESSING\n",
    "\n",
    "win = make_cosine_window(patch_size)\n",
    "\n",
    "for idx, (img_path, tps_path, gt_path) in enumerate(pairs, 1):\n",
    "    stem = basename_noext(img_path)\n",
    "    print(f\"[{idx}/{len(pairs)}] {stem}\")\n",
    "    t0 = time.perf_counter()\n",
    "    try:\n",
    "        # Laden\n",
    "        large_img = tifffile.imread(img_path)\n",
    "        if large_img is None or large_img.ndim != 2:\n",
    "            raise ValueError(\"Erwarte zweidimensionales Graubild\")\n",
    "\n",
    "        tps_inv, _ = invert_mask(tps_path)            # 255 außerhalb TPS\n",
    "        img_masked = apply_mask(large_img, tps_inv)   # Bild auf TPS begrenzen\n",
    "\n",
    "        gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if gt is None:\n",
    "            raise FileNotFoundError(f\"GT nicht gefunden: {gt_path}\")\n",
    "        gt_bin = (gt > 0).astype(np.uint8) * 255\n",
    "        gt_masked = cv2.bitwise_and(gt_bin, tps_inv)  # GT auf TPS begrenzen\n",
    "\n",
    "        # HA Streifen aus verschobener Nullregion erzeugen\n",
    "        zero_mask = (img_masked == 0).astype(np.uint8) * 255\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        zero_mask = cv2.morphologyEx(zero_mask, cv2.MORPH_OPEN, kernel)\n",
    "        m_orig  = (zero_mask > 0).astype(np.uint8)\n",
    "        m_shift = shift_mask_binary(m_orig, dx=0, dy=-shift_px)\n",
    "        ha_mask = ((m_shift == 1) & (m_orig == 0)).astype(np.uint8) * 255\n",
    "\n",
    "        # Patch Bildung\n",
    "        assert img_masked.shape == gt_masked.shape == ha_mask.shape\n",
    "        H_orig, W_orig = img_masked.shape\n",
    "        img_pad = pad_to_multiple(img_masked, patch_size)\n",
    "        gt_pad  = pad_to_multiple(gt_masked,  patch_size)\n",
    "        ha_pad  = pad_to_multiple(ha_mask,    patch_size)\n",
    "\n",
    "        img_p = patchify.patchify(img_pad, (patch_size, patch_size), step=step)\n",
    "        gt_p  = patchify.patchify(gt_pad,  (patch_size, patch_size), step=step)\n",
    "        ha_p  = patchify.patchify(ha_pad,  (patch_size, patch_size), step=step)\n",
    "\n",
    "        img_patches, gt_patches, ha_patches, coords = [], [], [], []\n",
    "        for i in range(img_p.shape[0]):\n",
    "            for j in range(img_p.shape[1]):\n",
    "                y0 = i * step\n",
    "                x0 = j * step\n",
    "                img_patches.append(img_p[i, j])\n",
    "                gt_patches.append(gt_p[i, j].astype(np.uint8))\n",
    "                ha_patches.append(ha_p[i, j].astype(np.uint8))\n",
    "                coords.append((y0, x0))\n",
    "        img_patches = np.array(img_patches)\n",
    "        gt_patches  = np.array(gt_patches)\n",
    "        ha_patches  = np.array(ha_patches)\n",
    "        coords      = np.array(coords, dtype=np.int32)\n",
    "\n",
    "        # Inferenz mit SAM Standard und HA Box\n",
    "        N, H, W = img_patches.shape\n",
    "        probs = np.zeros((N, H, W), dtype=np.float32)\n",
    "\n",
    "        prompt_log = {\n",
    "            \"promptart\": \"box\",\n",
    "            \"quelle\": \"ha\",\n",
    "            \"parameter\": {\"margin\": margin, \"min_pixels\": min_px,\n",
    "                          \"patch_size\": patch_size, \"step\": step,\n",
    "                          \"shift_px\": shift_px},\n",
    "            \"prompts\": []\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for k in range(N):\n",
    "                img_patch = img_patches[k]\n",
    "                ha_patch  = ha_patches[k]\n",
    "\n",
    "                box = mask_to_box(ha_patch, margin=margin, min_pixels=min_px)\n",
    "\n",
    "                # Fallback Box wenn keine Region gefunden wurde\n",
    "                if box is None:\n",
    "                    h, w = img_patch.shape\n",
    "                    cy = max(0, min(h - 1, h // 2))\n",
    "                    band = 2\n",
    "                    y0b = max(0, cy - band)\n",
    "                    y1b = min(h - 1, cy + band)\n",
    "                    box = [0, y0b, w - 1, y1b]\n",
    "\n",
    "                x0, y0, x1, y1 = box\n",
    "                pil_img = Image.fromarray(img_patch).convert(\"RGB\")\n",
    "\n",
    "                inputs = processor(\n",
    "                    images=pil_img,\n",
    "                    input_boxes=[[[x0, y0, x1, y1]]],\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                inputs = {kk: vv.to(device) for kk, vv in inputs.items()}\n",
    "\n",
    "                #out = sam_model(**inputs, multimask_output=False) # Für untrainierten SAM\n",
    "                out = my_HA_model(**inputs, multimask_output=False) # Für trainierten SAM\n",
    "                p_map = torch.sigmoid(out.pred_masks[0, 0, 0])  # Form H mal W\n",
    "                probs[k] = p_map.cpu().numpy()\n",
    "\n",
    "                gy, gx = int(coords[k][0]), int(coords[k][1])\n",
    "                box_global = [float(x0 + gx), float(y0 + gy), float(x1 + gx), float(y1 + gy)]\n",
    "                prompt_log[\"prompts\"].append({\n",
    "                    \"patch_index\": int(k),\n",
    "                    \"patch_top_left\": [gy, gx],\n",
    "                    \"box_global_xyxy\": box_global\n",
    "                })\n",
    "\n",
    "        # Rekonstruktion\n",
    "        H_pad = ceil_to_multiple(H_orig, patch_size)\n",
    "        W_pad = ceil_to_multiple(W_orig, patch_size)\n",
    "\n",
    "        full_prob = reconstruct_overlapping(probs, coords, H_pad, W_pad, patch_size, win)\n",
    "        full_pred = (full_prob > final_thr).astype(np.uint8) * 255\n",
    "        full_img  = reconstruct_overlapping(img_patches.astype(np.float32), coords, H_pad, W_pad, patch_size, win)\n",
    "        full_gt   = reconstruct_overlapping_binary(gt_patches, coords, H_pad, W_pad, patch_size)\n",
    "\n",
    "        # Zuschnitt auf Originalmaß\n",
    "        full_img_c  = full_img[:H_orig, :W_orig]\n",
    "        full_prob_c = full_prob[:H_orig, :W_orig]\n",
    "        full_pred_c = full_pred[:H_orig, :W_orig]\n",
    "        full_gt_c   = full_gt[:H_orig, :W_orig]\n",
    "\n",
    "        # Artefakte speichern\n",
    "        prob_u8 = np.rint(np.clip(full_prob_c * 255.0, 0, 255)).astype(np.uint8)\n",
    "        prob_dir = os.path.join(out_folder, \"prob_maps\")\n",
    "        os.makedirs(prob_dir, exist_ok=True)\n",
    "        out_prob = os.path.join(prob_dir, f\"{stem}_prob.png\")\n",
    "\n",
    "        pred_dir = os.path.join(out_folder, \"pred_masks\")\n",
    "        os.makedirs(pred_dir, exist_ok=True)\n",
    "        out_pred = os.path.join(pred_dir, f\"{stem}_pred.png\")\n",
    "\n",
    "        gt_dir = os.path.join(out_folder, \"gt_mask\")\n",
    "        os.makedirs(gt_dir, exist_ok=True)\n",
    "        out_gt = os.path.join(gt_dir, f\"{stem}_gt.png\")\n",
    "\n",
    "        cv2.imwrite(out_prob, prob_u8)\n",
    "        cv2.imwrite(out_pred, full_pred_c)\n",
    "        cv2.imwrite(out_gt,   full_gt_c)\n",
    "\n",
    "        # Dickenprofile\n",
    "        th_pred = thickness_per_column(full_pred_c)\n",
    "        th_gt   = thickness_per_column(full_gt_c)\n",
    "\n",
    "        thickness_pred_dir = os.path.join(out_folder, \"thickness_pred\")\n",
    "        os.makedirs(thickness_pred_dir, exist_ok=True)\n",
    "        out_th_pred = os.path.join(thickness_pred_dir, f\"{stem}_thickness_pred.csv\")\n",
    "\n",
    "        thickness_gt_dir = os.path.join(out_folder, \"thickness_gt\")\n",
    "        os.makedirs(thickness_gt_dir, exist_ok=True)\n",
    "        out_th_gt   = os.path.join(thickness_gt_dir, f\"{stem}_thickness_gt.csv\")\n",
    "\n",
    "        idxs = np.arange(W_orig, dtype=np.int32)\n",
    "        np.savetxt(out_th_pred, np.c_[idxs, th_pred], delimiter=\",\",\n",
    "                   header=\"spaltenindex,dicke_pixel\", fmt=\"%d\", comments=\"\")\n",
    "        np.savetxt(out_th_gt,   np.c_[idxs, th_gt],   delimiter=\",\",\n",
    "                   header=\"spaltenindex,dicke_pixel\", fmt=\"%d\", comments=\"\")\n",
    "\n",
    "        # Bildmetriken\n",
    "        dice, iou = dice_iou(full_pred_c, full_gt_c)\n",
    "        diff = th_pred.astype(np.int32) - th_gt.astype(np.int32)\n",
    "        mae  = float(np.mean(np.abs(diff))) if diff.size else 0.0\n",
    "        bias = float(np.mean(diff)) if diff.size else 0.0\n",
    "        mabs = int(np.max(np.abs(diff))) if diff.size else 0\n",
    "        cover = coverage_recall(full_pred_c, full_gt_c)\n",
    "        t_ms = (time.perf_counter() - t0) * 1000.0\n",
    "\n",
    "        metrics_dir = os.path.join(out_folder, \"metrics\")\n",
    "        os.makedirs(metrics_dir, exist_ok=True)\n",
    "\n",
    "        metrics = {\n",
    "            \"dice\": dice,\n",
    "            \"iou\": iou,\n",
    "            \"mae_dicke\": mae,\n",
    "            \"bias_dicke\": bias,\n",
    "            \"max_abs_err\": mabs,\n",
    "            \"abdeckung\": cover,\n",
    "            \"laufzeit_ms\": float(round(t_ms, 1))\n",
    "        }\n",
    "        with open(os.path.join(metrics_dir, f\"{stem}_metrics.json\"), \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "\n",
    "        # Prompt Protokoll\n",
    "        prompts_dir = os.path.join(out_folder, \"prompts\")\n",
    "        os.makedirs(prompts_dir, exist_ok=True)\n",
    "        with open(os.path.join(prompts_dir, f\"{stem}_prompt_protokoll.json\"), \"w\") as f:\n",
    "            json.dump(prompt_log, f, indent=2)\n",
    "\n",
    "        # Bildmetadaten\n",
    "        metadata_dir = os.path.join(out_folder, \"metadata\")\n",
    "        os.makedirs(metadata_dir, exist_ok=True)\n",
    "        metadata = {\n",
    "            \"bildkennung\": stem,\n",
    "            \"patchgroesse\": int(patch_size),\n",
    "            \"schrittweite\": int(step),\n",
    "            \"ueberlappung\": float(step / patch_size),\n",
    "            \"schwellenwert\": float(final_thr),\n",
    "            \"verwendete_nachbearbeitung\": \"keine\",\n",
    "            \"prompt_quelle\": \"ha\",\n",
    "            \"ha_shift_px\": int(shift_px),\n",
    "            \"blending\": \"cosine_window_hanning_eps1e-3\",\n",
    "            \"prob_map_skalierung\": \"round(prob*255)\"\n",
    "        }\n",
    "        with open(os.path.join(metadata_dir, f\"{stem}_bildmetadaten.json\"), \"w\") as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "\n",
    "        # Visualisierung\n",
    "        if save_viz:\n",
    "            viz_dir = os.path.join(out_folder, \"viz\")\n",
    "            os.makedirs(viz_dir, exist_ok=True)\n",
    "            fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "            axes[0].imshow(full_img_c, cmap=\"gray\"); axes[0].set_title(\"Bild\"); axes[0].axis(\"off\")\n",
    "            axes[1].imshow(full_gt_c, cmap=\"gray\");  axes[1].set_title(\"GT\"); axes[1].axis(\"off\")\n",
    "            axes[2].imshow(prob_u8, vmin=0, vmax=255); axes[2].set_title(\"Wahrscheinlichkeit\"); axes[2].axis(\"off\")\n",
    "            axes[3].imshow(full_pred_c, cmap=\"gray\"); axes[3].set_title(\"Vorhersage\"); axes[3].axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(viz_dir, f\"{stem}_viz.png\"), dpi=150)\n",
    "            plt.close(fig)\n",
    "\n",
    "        print(f\"{stem}: prob, pred, profile und JSON gespeichert\")\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei {stem}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCV66U6bruw5"
   },
   "source": [
    "# Berechnung des Vorhersagefehlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "fXS49Jlcr2xJ",
    "outputId": "0d477544-08e9-4e00-bfa4-1edd823b0fe1"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Pfade\n",
    "base_dir = Path(\"/content/drive/MyDrive/Colab Notebooks/Bachelor/Plots/Plots_Von_07_09/5e-5/inference\")\n",
    "pred_dir = base_dir / \"thickness_pred\"\n",
    "gt_dir   = base_dir / \"thickness_gt\"\n",
    "\n",
    "# ---------- Helfer ----------\n",
    "\n",
    "def has_header(csv_path):\n",
    "    \"\"\"Erkennt simpel, ob die erste Zeile eher Header ist.\"\"\"\n",
    "    with open(csv_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        first = f.readline()\n",
    "    # Wenn Buchstaben in der ersten Zeile stecken, werten wir das als Header\n",
    "    return bool(re.search(r'[A-Za-zÄÖÜäöü]', first))\n",
    "\n",
    "def read_thickness_csv(csv_path):\n",
    "    \"\"\"Liest eine 2-Spalten-CSV: [spaltenindex, dicke_pixel]. Robust gegen Header und Dezimalkomma.\"\"\"\n",
    "    if has_header(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # versuche die wahrscheinlichsten Spaltennamen\n",
    "        cols = list(df.columns)\n",
    "        if len(cols) < 2:\n",
    "            # Fallback: ohne Header lesen\n",
    "            df = pd.read_csv(csv_path, header=None, names=[\"spaltenindex\", \"dicke_pixel\"])\n",
    "        else:\n",
    "            # mappe möglichst auf Standardnamen\n",
    "            mapping = {}\n",
    "            # erstbeste zwei Spalten nehmen, aber sinnvoll benennen\n",
    "            mapping[cols[0]] = \"spaltenindex\"\n",
    "            mapping[cols[1]] = \"dicke_pixel\"\n",
    "            df = df.rename(columns=mapping)[[\"spaltenindex\", \"dicke_pixel\"]]\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path, header=None, names=[\"spaltenindex\", \"dicke_pixel\"])\n",
    "\n",
    "    # Dezimalkomma abfangen und auf float casten\n",
    "    for c in [\"spaltenindex\", \"dicke_pixel\"]:\n",
    "        ser = df[c].astype(str).str.replace(',', '.', regex=False)\n",
    "        df[c] = pd.to_numeric(ser, errors='coerce')\n",
    "\n",
    "    # sortieren, Duplikate im Index vermeiden\n",
    "    df = df.drop_duplicates(subset=[\"spaltenindex\"]).sort_values(\"spaltenindex\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def clean_stem(p: Path):\n",
    "    \"\"\"Entfernt trailing _pred oder _gt aus dem Dateinamenstamm.\"\"\"\n",
    "    stem = p.stem  # ohne .csv\n",
    "    stem = re.sub(r'_(pred|gt)$', '', stem, flags=re.IGNORECASE)\n",
    "    return stem\n",
    "\n",
    "def compute_metrics(errors: np.ndarray, total_cols: int):\n",
    "    \"\"\"\n",
    "    Gibt Kennwerte als Dict zurück.\n",
    "    errors: 1D-Array der validen Fehler e(j) = d_pred - d_ref\n",
    "    total_cols: Gesamtzahl der Spalten (vor Filter), für Abdeckung\n",
    "    \"\"\"\n",
    "    W = int(np.sum(np.isfinite(errors)))\n",
    "    if W == 0:\n",
    "        return dict(W=0, total_columns=int(total_cols), coverage=np.nan,\n",
    "                    MAE=np.nan, Bias=np.nan, Std=np.nan,\n",
    "                    CI95_lower=np.nan, CI95_upper=np.nan,\n",
    "                    MaxAbsError=np.nan)\n",
    "\n",
    "    e = errors[np.isfinite(errors)]\n",
    "    mae = float(np.mean(np.abs(e)))\n",
    "    bias = float(np.mean(e))\n",
    "    std = float(np.std(e, ddof=1)) if W > 1 else np.nan\n",
    "\n",
    "    if W > 1 and np.isfinite(std):\n",
    "        tcrit = stats.t.ppf(0.975, df=W-1)\n",
    "        half_width = tcrit * std / math.sqrt(W)\n",
    "        ci_lo = bias - half_width\n",
    "        ci_hi = bias + half_width\n",
    "    else:\n",
    "        ci_lo = np.nan\n",
    "        ci_hi = np.nan\n",
    "\n",
    "    max_abs = float(np.max(np.abs(e)))\n",
    "    coverage = float(W / total_cols) if total_cols > 0 else np.nan\n",
    "\n",
    "    return dict(W=W, total_columns=int(total_cols), coverage=coverage,\n",
    "                MAE=mae, Bias=bias, Std=std,\n",
    "                CI95_lower=ci_lo, CI95_upper=ci_hi,\n",
    "                MaxAbsError=max_abs)\n",
    "\n",
    "# ---------- Dateien paaren ----------\n",
    "\n",
    "pred_files = list(pred_dir.glob(\"*.csv\"))\n",
    "gt_files   = list(gt_dir.glob(\"*.csv\"))\n",
    "\n",
    "pred_map = {clean_stem(p): p for p in pred_files}\n",
    "gt_map   = {clean_stem(p): p for p in gt_files}\n",
    "\n",
    "common_stems = sorted(set(pred_map.keys()) & set(gt_map.keys()))\n",
    "missing_pred = sorted(set(gt_map.keys()) - set(pred_map.keys()))\n",
    "missing_gt   = sorted(set(pred_map.keys()) - set(gt_map.keys()))\n",
    "\n",
    "if missing_pred:\n",
    "    print(\"Warnung: Es fehlen _pred Dateien für:\", missing_pred)\n",
    "if missing_gt:\n",
    "    print(\"Warnung: Es fehlen _gt Dateien für:\", missing_gt)\n",
    "\n",
    "# ---------- Metriken je Paar und gesamt ----------\n",
    "\n",
    "rows = []\n",
    "all_errors = []\n",
    "\n",
    "for stem in common_stems:\n",
    "    df_pred = read_thickness_csv(pred_map[stem]).rename(columns={\"dicke_pixel\": \"d_pred\"})\n",
    "    df_gt   = read_thickness_csv(gt_map[stem]).rename(columns={\"dicke_pixel\": \"d_ref\"})\n",
    "\n",
    "    # Outer-Join auf Spaltenindex, um Gesamtzahl der Spalten zu bestimmen\n",
    "    merged = pd.merge(df_pred[[\"spaltenindex\", \"d_pred\"]],\n",
    "                      df_gt[[\"spaltenindex\", \"d_ref\"]],\n",
    "                      on=\"spaltenindex\", how=\"outer\", sort=True)\n",
    "\n",
    "    # Gesamtzahl vor dem Filter\n",
    "    total_cols = merged[\"spaltenindex\"].nunique()\n",
    "\n",
    "    # valide Paare: beide Werte endlich\n",
    "    valid = merged[[\"d_pred\", \"d_ref\"]].apply(np.isfinite).all(axis=1)\n",
    "    merged_valid = merged.loc[valid].copy()\n",
    "\n",
    "    # Fehler\n",
    "    merged_valid[\"e\"] = merged_valid[\"d_pred\"] - merged_valid[\"d_ref\"]\n",
    "\n",
    "    # Kennwerte\n",
    "    metrics = compute_metrics(merged_valid[\"e\"].to_numpy(), total_cols)\n",
    "    metrics[\"datei_stamm\"] = stem\n",
    "    rows.append(metrics)\n",
    "\n",
    "    # für Gesamt\n",
    "    all_errors.append(merged_valid[\"e\"].to_numpy())\n",
    "\n",
    "# Gesamt über alle Paare\n",
    "if all_errors:\n",
    "    all_errors_vec = np.concatenate(all_errors)\n",
    "    total_cols_sum = sum(r[\"total_columns\"] for r in rows)  # Summe der Spalten über alle Dateien\n",
    "    overall = compute_metrics(all_errors_vec, total_cols_sum)\n",
    "    overall[\"datei_stamm\"] = \"ALLE_DATEIEN\"\n",
    "    rows.append(overall)\n",
    "\n",
    "# ---------- Ergebnis als Tabelle ----------\n",
    "\n",
    "cols_order = [\"datei_stamm\", \"W\", \"total_columns\", \"coverage\",\n",
    "              \"MAE\", \"Bias\", \"Std\", \"CI95_lower\", \"CI95_upper\", \"MaxAbsError\"]\n",
    "\n",
    "result_df = pd.DataFrame(rows)[cols_order]\n",
    "\n",
    "# etwas aufräumen und runden\n",
    "num_cols = [\"coverage\", \"MAE\", \"Bias\", \"Std\", \"CI95_lower\", \"CI95_upper\", \"MaxAbsError\"]\n",
    "result_df[num_cols] = result_df[num_cols].astype(float).round(6)\n",
    "\n",
    "# speichern\n",
    "out_path = base_dir / \"thickness_metrics_summary_2.csv\"\n",
    "result_df.to_csv(out_path, index=False)\n",
    "print(f\"Fertig. Zusammenfassung gespeichert unter:\\n{out_path}\")\n",
    "\n",
    "# erste Zeilen zeigen\n",
    "result_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
